Class 3: Language modeling
---------------------------

## Videos

[Language Modeling Playlist - videos 3_1-3_8](https://www.youtube.com/watch?v=hM49MPmakNI&list=PLaZQkZp6WhWwJllbfwOD9cbIHXmdkOICY)
(Optional: Speeling correction videos, 4_1-4_4) 

## Reading 

J+M (3ed) Chapter 3, ["Language Modeling with N-grams" pages 1-16 (plus section 3.6, "The Web and Stupid Backoff")](https://web.stanford.edu/~jurafsky/slp3/3.pdf)

## Exercises (optional - may cover material beyond required readings)

*[From J+M (3ed) Chapter 3, "Language Modeling with N-grams"](https://web.stanford.edu/~jurafsky/slp3/3.pdf)

3.1 Write out the equation for trigram probability estimation (modifying Eq. 3.11).

3.8 Write a program to compute unsmoothed unigrams and bigrams.

3.9 Run your n-gram program on two different small corpora of your choice (you
might use email text or newsgroups). Now compare the statistics of the two
corpora. What are the differences in the most common unigrams between the
two? How about interesting differences in bigrams?

3.10 Add an option to your program to generate random sentences.

3.11 Add an option to your program to compute the perplexity of a test set.


Note: Please send your answers via [this link](mailto:rebekahbrita@gmail.com?subject=AUNLP:%20Chapter%203%20Answers) by **Friday September 27 at 5pm.** 




