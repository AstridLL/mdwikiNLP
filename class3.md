Class 3: Language modeling
---------------------------

## Videos

[Language Modeling Playlist - videos 4_1-4_8](https://www.youtube.com/playlist?list=PLSI4up6RakkhmHgbaMCiDaxL-uOmAKoHH) (The Spelling correction videos, 5_1-5_4, are **optional**) 

(Playlist duration (minus Spelling Correction)) = 1 hour, 15 minutes) 


## Reading 

J+M (3ed) Chapter 3, ["Language Modeling with N-grams" pages 1-16 (plus section 3.6, "The Web and Stupid Backoff")](https://web.stanford.edu/~jurafsky/slp3/3.pdf)

## Group Exercises 

*[From J+M (3ed) Chapter 3, "Language Modeling with N-grams"](https://web.stanford.edu/~jurafsky/slp3/3.pdf)

3.1 Write out the equation for trigram probability estimation (modifying Eq. 3.11).

3.8 Write a program to compute unsmoothed unigrams and bigrams.

3.9 Run your n-gram program on two different small corpora of your choice (you
might use email text or newsgroups). Now compare the statistics of the two
corpora. What are the differences in the most common unigrams between the
two? How about interesting differences in bigrams?

3.10 Add an option to your program to generate random sentences.

3.11 Add an option to your program to compute the perplexity of a test set.


Note: Please message your answers on Slack (your study group + Rebekah + Kenneth) by Wednesday 8am




